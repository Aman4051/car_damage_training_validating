{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c0c04-b929-4042-b30e-840f70099a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Training set size: 651\n",
      "Validation set size: 163\n",
      "--- Starting Stage 1: Training the Head ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [07:19<00:00, 10.72s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:51<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Training Epoch 1/5 - Train Loss: 0.8398, Train IoU: 0.2267, Val Loss: 0.7709, Val IoU: 0.2898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [07:15<00:00, 10.63s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:51<00:00,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Training Epoch 2/5 - Train Loss: 0.8338, Train IoU: 0.4081, Val Loss: 0.7628, Val IoU: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [07:16<00:00, 10.65s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:50<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Training Epoch 3/5 - Train Loss: 0.8279, Train IoU: 0.4221, Val Loss: 0.7594, Val IoU: 0.4028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [07:19<00:00, 10.72s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:51<00:00,  4.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Training Epoch 4/5 - Train Loss: 0.8097, Train IoU: 0.4034, Val Loss: 0.7580, Val IoU: 0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [07:20<00:00, 10.75s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:50<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head Training Epoch 5/5 - Train Loss: 0.8201, Train IoU: 0.3998, Val Loss: 0.7552, Val IoU: 0.4476\n",
      "\n",
      "--- Starting Stage 2: Fine-Tuning Full Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [09:50<00:00, 14.40s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:50<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Training Epoch 1/20 - Train Loss: 0.7971, Train IoU: 0.4031, Val Loss: 0.7537, Val IoU: 0.4756\n",
      "  New best model saved with IoU: 0.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [09:46<00:00, 14.30s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:50<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Training Epoch 2/20 - Train Loss: 0.8125, Train IoU: 0.4048, Val Loss: 0.7532, Val IoU: 0.4591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [10:02<00:00, 14.70s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:51<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Training Epoch 3/20 - Train Loss: 0.8225, Train IoU: 0.4067, Val Loss: 0.7520, Val IoU: 0.4616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 41/41 [09:48<00:00, 14.36s/it]\n",
      "Validating: 100%|██████████| 11/11 [00:51<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Training Epoch 4/20 - Train Loss: 0.8104, Train IoU: 0.4088, Val Loss: 0.7512, Val IoU: 0.4404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|███▋      | 15/41 [04:18<07:09, 16.54s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from skimage.draw import polygon\n",
    "from segmentation_models_pytorch import MAnet\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "from segmentation_models_pytorch.metrics import get_stats, iou_score\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "\n",
    "def retrieve_meta_data(path):\n",
    "    MetaJson = json.load(open(path, \"r\"))\n",
    "    class_titles = []\n",
    "    class_ids = []\n",
    "    for cls in MetaJson[\"classes\"]:\n",
    "        class_titles.append(cls[\"title\"])\n",
    "        class_ids.append(cls['id'])\n",
    "    return class_titles, class_ids\n",
    "\n",
    "class CarDataLoader(Dataset):\n",
    "    def __init__(self, transforms, imgs_path, annotations_path, classes, sizes, files=None):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.annotations_path = annotations_path\n",
    "        self.classes = classes\n",
    "        self.transforms = transforms\n",
    "        self.sizes = sizes\n",
    "        if files is not None:\n",
    "            self.images = sorted(files)  # Use the specified files\n",
    "        else:\n",
    "            self.images = sorted(os.listdir(imgs_path))  # Original behavior\n",
    "            \n",
    "        self.annotations = [x + \".json\" for x in self.images]\n",
    "\n",
    "    @staticmethod\n",
    "    def getMask(sizes, annfile, classes):\n",
    "        img_height, img_width = annfile[\"size\"][\"height\"], annfile[\"size\"][\"width\"]\n",
    "        mask = torch.zeros((img_height, img_width), dtype=torch.long)\n",
    "        mask_numpy = mask.numpy()\n",
    "        for object_ in annfile[\"objects\"]:\n",
    "            class_id = classes.index(object_[\"classId\"])\n",
    "            points = np.asarray(object_[\"points\"][\"exterior\"])\n",
    "            rr, cc = polygon(points[:, 1], points[:, 0], (img_height, img_width))\n",
    "            mask_numpy[rr, cc] = class_id + 1\n",
    "        \n",
    "        mask_tensor = transforms.Resize(sizes, interpolation=transforms.InterpolationMode.NEAREST)(torch.from_numpy(mask_numpy).unsqueeze(0))\n",
    "        \n",
    "        # Create one-hot encoded mask\n",
    "        num_classes = len(classes) + 1 # Add 1 for background\n",
    "        one_hot_mask = torch.nn.functional.one_hot(mask_tensor.long(), num_classes=num_classes)\n",
    "        one_hot_mask = one_hot_mask.permute(0, 3, 1, 2).squeeze(0).float()\n",
    "        return one_hot_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.imgs_path, self.images[idx])\n",
    "        ann_path = os.path.join(self.annotations_path, self.annotations[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        ann = json.load(open(ann_path, \"r\"))\n",
    "        \n",
    "        mask_tensor = CarDataLoader.getMask(self.sizes, ann, self.classes)\n",
    "        img_tensor = self.transforms(img)\n",
    "        \n",
    "        return img_tensor, mask_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    for images, masks in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tp, fp, fn, tn = get_stats(outputs, masks.long(), mode=\"multilabel\", threshold=0.5)\n",
    "        iou = iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_iou += iou.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    return epoch_loss, epoch_iou\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(dataloader, desc=\"Validating\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            tp, fp, fn, tn = get_stats(outputs, masks.long(), mode=\"multilabel\", threshold=0.5)\n",
    "            iou = iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_iou += iou.item()\n",
    "            \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    return epoch_loss, epoch_iou\n",
    "\n",
    "class config:\n",
    "    def __init__(self, img_dir, ann_dir, meta_path, sizes, batch_size, learning_rate, backbone, head_epochs, full_model_epochs, save_path):\n",
    "        self.img_dir = img_dir\n",
    "        self.ann_dir = ann_dir\n",
    "        self.meta_path = meta_path\n",
    "        self.sizes = sizes\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.backbone = backbone\n",
    "        self.head_epochs = head_epochs\n",
    "        self.full_model_epochs = full_model_epochs\n",
    "        self.save_path = save_path\n",
    "\n",
    "def main(config):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    class_titles, classes_ids = retrieve_meta_data(config.meta_path)\n",
    "    num_classes = len(classes_ids) + 1 # +1 for the background\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "    transforms.Resize(config.sizes),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# One without augmentations for validation\n",
    "    val_transform = transforms.Compose([\n",
    "    transforms.Resize(config.sizes),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "   ])\n",
    "    \n",
    "    # --- Dataset Splitting ---\n",
    "    all_image_files = sorted(os.listdir(config.img_dir))\n",
    "    random.shuffle(all_image_files)\n",
    "    split_idx = int(0.8 * len(all_image_files))\n",
    "    train_files = all_image_files[:split_idx]\n",
    "    val_files = all_image_files[split_idx:]\n",
    "\n",
    "    train_dataset = CarDataLoader(train_transform, config.img_dir, config.ann_dir, classes_ids, config.sizes, train_files)\n",
    "    val_dataset = CarDataLoader(val_transform, config.img_dir, config.ann_dir, classes_ids, config.sizes, val_files)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    print(f\"Training set size: {len(train_dataset)}\")\n",
    "    print(f\"Validation set size: {len(val_dataset)}\")\n",
    "    \n",
    "    # --- Model, Loss, Optimizer ---\n",
    "    model = smp.MAnet(encoder_name=config.backbone, encoder_weights=\"imagenet\", classes=num_classes)\n",
    "    model.to(device)\n",
    "    criterion = DiceLoss(mode=\"multilabel\")\n",
    "    \n",
    "    print(\"--- Starting Stage 1: Training the Head ---\")\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(trainable_params, lr=config.learning_rate)\n",
    "    \n",
    "    for epoch in range(config.head_epochs):\n",
    "        train_loss, train_iou = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_iou = validate(model, val_loader, criterion, device)\n",
    "        print(f\"Head Training Epoch {epoch+1}/{config.head_epochs} - Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Starting Stage 2: Fine-Tuning Full Model ---\")\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = True\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate / 10)\n",
    "    best_iou = -1.0\n",
    "    \n",
    "    for epoch in range(config.full_model_epochs):\n",
    "        train_loss, train_iou = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_iou = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Full Training Epoch {epoch+1}/{config.full_model_epochs} - Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}\")\n",
    "        \n",
    "        if val_iou > best_iou:\n",
    "            best_iou = val_iou\n",
    "            torch.save(model.state_dict(), config.save_path)\n",
    "            print(f\"  New best model saved with IoU: {best_iou:.4f}\")\n",
    "\n",
    "# Declaring folder paths for images and masks\n",
    "training_config = config(\"C:/Users/Armaan/Downloads/archive/Car parts dataset/File1/img\",\n",
    "                         \"C:/Users/Armaan/Downloads/archive/Car parts dataset/File1/ann\",\n",
    "                         \"C:/Users/Armaan/Downloads/archive/Car parts dataset/meta.json\",\n",
    "                         (320, 320),\n",
    "                         16,\n",
    "                         1e-4,\n",
    "                         'resnet50',\n",
    "                         5,\n",
    "                         20,\n",
    "                         'best_part_model_resnet50.pth'\n",
    "                     )\n",
    "main(training_config)\n",
    "\n",
    "# Declaring folder paths for images and masks\n",
    "training_config = config(\"C:/Users/Armaan/Downloads/archive/Car damages dataset/File1/img\",\n",
    "                         \"C:/Users/Armaan/Downloads/archive/Car damages dataset/File1/ann\",\n",
    "                         \"C:/Users/Armaan/Downloads/archive/Car damages dataset/meta.json\",\n",
    "                         (320, 320),\n",
    "                         16,\n",
    "                         1e-4,\n",
    "                         'resnet50',\n",
    "                         5,\n",
    "                         20,\n",
    "                         'best_damage_model_resnet50.pth'\n",
    "                     )\n",
    "main(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08159e4-ea3d-48ab-a314-c9932bb5e346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d44110-e6d2-4f25-b114-bb9ebeef0a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
